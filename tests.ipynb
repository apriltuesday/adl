{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Graph, Sequential\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.core import AutoEncoder, Dense, Activation, TimeDistributedDense, Flatten, Dropout, RepeatVector\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.metrics import precision_recall_curve, precision_recall_fscore_support, f1_score\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.utils.visualize_util import plot\n",
    "\n",
    "from helper import *\n",
    "from lstm_networks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "vocabulary_size = 196\n",
    "embedding_size = 10\n",
    "encoding_size = 30\n",
    "decoding_size = 10\n",
    "sequence_length = 90\n",
    "n_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Graph()\n",
    "model.add_input(name='input', input_shape=(sequence_length,), dtype=int) # or (vocabulary_size?)\n",
    "\n",
    "# Encoding input into a representation\n",
    "model.add_node(Embedding(vocabulary_size, embedding_size, input_length=sequence_length),\n",
    "               name='embedding',\n",
    "               input='input')\n",
    "model.add_node(LSTM(encoding_size, input_length=sequence_length, return_sequences=True),\n",
    "               name='encoder',\n",
    "               input='embedding')\n",
    "\n",
    "# Branch 1: reconstruct\n",
    "model.add_node(LSTM(decoding_size, return_sequences=True),\n",
    "               name='decoder',\n",
    "               input='encoder')\n",
    "model.add_node(TimeDistributedDense(vocabulary_size, activation='softmax'),\n",
    "               name='distributed',\n",
    "               input='decoder')\n",
    "model.add_output(name='reconstruction', input='distributed')\n",
    "\n",
    "# Branch 2: classify\n",
    "model.add_node(Flatten(), name='flatten', input='encoder')\n",
    "model.add_node(Dropout(0.5), name='dropout', input='flatten')\n",
    "model.add_node(Dense(1, activation='sigmoid'),\n",
    "               name='dense',\n",
    "               input='dropout')\n",
    "model.add_output(name='classification', input='dense')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss={'reconstruction':'mse', 'classification':'binary_crossentropy'}) # XXX mse?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
